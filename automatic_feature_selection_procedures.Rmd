---
title: "A Review of Automatic Feature Selection Processes in R"
author: "Michael Najarro"
date: "12/5/2020"
output: github_document
---

#*Objective*
This report demonstrates automatic feature selection procedure (AFSP) tools in R. AFSPs expedite the data processing procedures commonly performed prior to implementing Machine Learning or Artifical Intelligence algorithms.

Due to limitations of my hardware and for the purposes of testing AFSPs, I  work with several data sets to demonstrate the following AFSP packages in R:
  1. Boruta
  
  2. LASSO
  
  3. Vtreat
  
  4. Vsurf
  
  5. Genetic algorithm (GA)


# *Boruta*

Written by Miron B. Kursa and Witold R. Rudnicki (https://www.jstatsoft.org/article/view/v036i11).

Boruta aids in selecting the most minimally optimal variables from a large pool of features that maximize classification by implementing wrapper algorthims that avoids the influential effects of selection by accuracy.

Boruta eseentially implements a two sample Z-test, comparing Z scores of the average loss of accuracy generated from a random forest applied to the ranked features of the data set to the Z scores of "shadow features" created from each variable. The shadow features are randomly selected values from a given variable. The comparison essentially evlautes the standing of a given variable relative to its imposter of random noise; if 
its los of accuracy is not smaller than random noise, it is excluded.

I demosntrate an example of Boruta below on the manually selected data of the Kaggle Lending Club analysis report (LC_Analysis.Rmd).

If one has access to more extensive hardware, one could modify and apply these algorithms to the original Kaggle Lending CLub data set, with some minor processing (cleaning steps would be to convert the response variable to a factor format, remove NAS, and depending on the procedure,remove factor variables).

Please note that in phase five of the Boruta AFSP, I implement the same machine learning processes found in the Kaggle data analysis project, to compare the reduced feature analysis to my original analysis. One may skip the immplementation of Boruta (the process took approximately 5 hours using 2nd generation Intel i5 M520 2 core processor with 8 GB of RAM) and load data based on Boruta's recommendation by going directly to phase 5 and implementing its code.


```{r}
library(pacman)
p_load(Boruta,
       tictoc)
```

## **Phase 1: Prepare your training and test data sets**

#### 1.a) load your data and create test and training sets

```{r}
#LCTF <- readRDS(file="./cleaneddata.rds")
refineddf <- readRDS(file = "./data/data_for_rf.rds" )

# create the test data
n <- nrow(refineddf)

# create the test data
test <- sample.int(n, size = round(0.25 * n))
test_set <- refineddf[test, ]
nrow(test_set)

#create the training data
train_set <- refineddf[-test,]
nrow(train_set)
```


## **Phase 2: Implement Boruta**

### 2.a) Implement Boruta on the training set

Implementing Boruta on a small laptop with 8 GB of ram and only two core processor took approximately 5.33 hours. Please consider your hardware and timing before running this step. 

```{r}
tic()
boruta.train <- Boruta(chance_default~., data = train_set, doTrace =  2)
toc()
```


### 2.b) assess Boruta's results

```{r}
# what were boruta's results?
boruta.train

# the decisions made per variable
boruta.train$finalDecision
```


a plot of the variable importance, based on the importance history output.

```{r}
plot(boruta.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(boruta.train$ImpHistory), function(i)
boruta.train$ImpHistory[is.finite(boruta.train$ImpHistory[,i]),i] )
names(lz) <- colnames(boruta.train$ImpHistory)
labels <- sort(sapply(lz,median))
axis(side = 1,
     las=2,
     labels = names(labels),
     at = 1:ncol(boruta.train$ImpHistory),
     cex.axis = 0.5)
```

```{r}
# pull out the importance history as a separate data frame
#a <- as.data.frame(boruta.train$ImpHistory)

# within each column, there may be infinity and negative infinity values. So you have to go through each column and pull out the numeric values.
#lz<-lapply(1:ncol(a), function(x) a[is.finite(boruta.train$ImpHistory[,x]),x] )

# convert the list to a data frame and label columns
#lz<- data.frame(matrix(unlist(lz), nrow = 99, byrow = FALSE))
#names(lz) <- colnames(a[,c(1:43)])

# now plot the summary of each element of lz
#ggplot2(data = lz, mapping = aes(x = ))

```


## **Phase 3: Use Boruta's recommendation to reduce the number of predictor variables forrandom forest model training**

```{r}
p_load(tidyverse, magrittr)

str(boruta.train$finalDecision)
levels(boruta.train$finalDecision)

# create a new vector of the final decisions
b <- c(boruta.train$finalDecision)

# identify the names of the elements that were confirmed.
j<-names(which(b==2))

#keep these columns in the original data set by tossing out others.
refineddf <- refineddf %>%
  select(all_of(j), chance_default)

saveRDS(object = refineddf, file = "./boruta_train_data.RDS")
```


### phase 4: evalution

Boruta reduced the number of variables from 45 to 37.

```{r}
bdata<- readRDS(file = "./data/boruta_train_data.RDS")
```


### phase 5: Run bortua features through random forest and compare to Kaggle data analysis project.
I here now Implement a Random Forest algorithm for classification on the Boruta reduced-feeatured data.








# LASSO

The Least absolute shrinkage and selection operator, written by Robert Tibshirani (https://beehive.cs.princeton.edu/course/read/tibshirani-jrssb-1996.pdf)

LASSO's goal is 

## **Phase 1: Load your data into the environment**

```{r}
refineddf <- readRDS(file = "./data/data_for_rf.rds" )
```


## **Phase 2: Process data to contain strictly numeric data**

Note that LASSO found in the glmnet package requires the use of all numeric values.

```{r}
a<- refineddf %>%
  select_if(is.numeric)

# 1 = safe, 0 = risk
a$chance_default <- as.numeric(as.factor(refineddf$chance_default)) - 1
x <- model.matrix(chance_default~., data = a)[,-33]
y <- a$chance_default
```


## **Phase 3: Implement LASSO**

```{r}
library(glmnet)

lasso_mod <- glmnet(x, y, alpha = 0)

set.seed(1443)
lasso_cvfit <- cv.glmnet(x, y, alpha=0)
lasso_cvfit$lambda.min # selected labda value

#plot with alpha threshold
plot(lasso_mod, xvar = "lambda")
abline(v=log(lasso_cvfit$lambda.min))

 
coef(lasso_cvfit, s="lambda.min")
lasso_coefs <- as.numeric(coef(lasso_cvfit, s="lambda.min"))
#sum(abs(lasso_coefs) > 0)
```



# Vtreat

Written by John Mount and Nina Zumel (https://github.com/WinVector/vtreat, https://arxiv.org/pdf/1611.09477.pdf).

A package conaining methods for preprocessing data for supervised machine learning or predictive modeling.

Vtreat takes a data frame with defined refined response and predictor variables and cleans the data by transforming all non-numeric columns to type numeric. Vtreat can deal with categorical variables that contain a large number of levels or exposure to new levels in the test data through sub modeling procedures.

Vtreat has a variety of built in methods to deal with processing issues, and several procedures depending on the type of machine learning algorithm and purpose one wishes to perform.

For this example, I will implement Vtreat for the purpose of supervised classification and I base my first example around the nested bias model found in Mount and Zumel's 2019 Arxive article. 

I then apply the "fit_prepare" classification example. This updated procedure to Vtreat, is based on Python's Scikit learn pipeline (https://github.com/WinVector/vtreat/blob/master/Examples/fit_transform/fit_prepare_api.md)

## **Phase 1: load initial data**

### 1.a) load your libraries and data
As a proof of demonstration, I will use the LCTF10 data used in my Kaggle Lending Club Analysis project.

```{r}
# libraries
p_load(vtreat, car, magrittr, tidyverse, rqdatatable)

LCTF10 <- readRDS(file = "./data/cleaneddata.rds" )
```

###1.b) Pre cleaning of data before Vtreat

Due to limitations in hardware and to prepare the data for vtreat, I first need to modify the response variable.

```{r}
# convert the response to a factor
LCTF10$borrower_status <- as.factor(LCTF10$borrower_status)

# create a new vector that avoids the space in the response variable's levels
possible_default <- as.factor(recode(as.vector(LCTF10$borrower_status), "'risky client'='risk'; 'safe client'='safe'"))

# add the vector to LCTF10
LCTF10 <- LCTF10 %>%
  mutate(chance_default = possible_default) %>%
  select(-borrower_status)
```


I then remove a few initial columns that are filled with or over 50% NAs.

```{r}
# create a function to determine which variables have
# less than or equal to 50% legit data:
d <- rep(0, ncol(LCTF10))
bad <- as.integer(rep(0, ncol(LCTF10)))
result<- as.character(rep(0, nrow(LCTF10)))

assess_bad_data<- function(df) {
d <<- (colSums(!is.na(LCTF10))/nrow(LCTF10))
bad <<- (which(d <=.50))
result <<- (colnames(LCTF10[bad]))
#return(result)
}
assess_bad_data(LCTF10)

#how many bad columns are there?
length(result)

#which are the bad columns(by column number)?
bad

# toss the bad variables from td.
LCTF10 <- LCTF10[-(bad)]

rm(bad,d,possible_default,result,assess_bad_data)
```


## **Phase 2: Build your transform**

Within the data are several columns containing NAs, and categorical variables with extreme cardinality (categorical levels with many levels.)

```{r}
library(Amelia)
missmap(LCTF10)
```

### 3.a) generate three sub groups

Vtreat documenation recommends splitting the data into three subsets to prevent overfitting: calibraition, training, and test sets. I perform these splits below.

```{r}
LCTF10$group <- sample(c("cal", "train", "test"),
                       nrow(LCTF10),
                       replace=TRUE,
                       prob=c(0.6, 0.2, 0.2))

Lcal <- LCTF10[LCTF10$group =='cal', , drop=FALSE]

Ltrain <- LCTF10[LCTF10$group =='train', , drop=FALSE]

Ltest <- LCTF10[LCTF10$group =='test', , drop=FALSE]
```


### 3.b) create the treatment plan on calibrated data

The next step is to create a designed treatment plan from the calibration data set. 

```{r}
colname <- names(Lcal[1:108])
Lcal<- Lcal[,-110]

("id",                        
"loan_amnt",                 
"funded_amnt",               
"funded_amnt_inv",           
"term",                  
"int_rate",                  
"installment",               
"grade",                     
"sub_grade",                
"emp_title",                 
"emp_length",                
"home_ownership",            
"annual_inc",                
"verification_status",       
"Issue_Month",               
"Issue_Year",                
"loan_status",               
"pymnt_plan",                
"url",                
"desc",                      
"purpose",                   
"title",                     
 "zip_code",                  
 "addr_state",                
 "dti",                       
 "delinq_2yrs",               
 "earliest_cr_line",          
 "fico_range_low",            
 "fico_range_high",           
 "inq_last_6mths",            
 "open_acc",                  
"pub_rec",                   
 "revol_bal",                 
 "revol_util",                
 "total_acc",                 
"initial_list_status",       
 "out_prncp",                 
 "out_prncp_inv",             
"total_pymnt",               
"total_pymnt_inv",           
"total_rec_prncp",           
"total_rec_int",            
"total_rec_late_fee",        
"recoveries",                
"collection_recovery_fee",   
"last_pymnt_d",              
"last_pymnt_amnt",           
"next_pymnt_d",              
"last_credit_pull_d",      
"last_fico_range_high",      
"last_fico_range_low",       
"collections_12_mths_ex_med",
 "policy_code",               
 "application_type",          
 "verification_status_joint", 
 "acc_now_delinq",            
 "tot_coll_amt",              
 "tot_cur_bal",               
 "total_rev_hi_lim",          
 "acc_open_past_24mths",      
 "avg_cur_bal",               
 "bc_open_to_buy",            
 "bc_util",                   
 "chargeoff_within_12_mths",  
 "delinq_amnt",               
"mo_sin_old_il_acct",        
 "mo_sin_old_rev_tl_op",      
 "mo_sin_rcnt_rev_tl_op",     
 "mo_sin_rcnt_tl",            
 "mort_acc",                  
 "mths_since_recent_bc",      
 "mths_since_recent_inq",     
 "num_accts_ever_120_pd",     
 "num_actv_bc_tl",            
 "num_actv_rev_tl",           
 "num_bc_sats",               
 "num_bc_tl",                 
 "num_il_tl",                 
 "num_op_rev_tl",             
 "num_rev_accts",             
 "num_rev_tl_bal_gt_0",       
 "num_sats",                  
 "num_tl_120dpd_2m",          
 "num_tl_30dpd",              
 "num_tl_90g_dpd_24m",        
 "num_tl_op_past_12m",        
 "pct_tl_nvr_dlq",            
 "percent_bc_gt_75",          
 "pub_rec_bankruptcies",      
 "tax_liens",                 
 "tot_hi_cred_lim",           
 "total_bal_ex_mort",         
 "total_bc_limit",            
 "total_il_high_credit_limit",
 "sec_app_earliest_cr_line",  
 "hardship_flag",             
 "hardship_type",             
 "hardship_reason",          
 "hardship_status",           
 "hardship_start_date",       
 "hardship_end_date",         
 "payment_plan_start_date",   
 "hardship_loan_status",      
 "disbursement_method",       
 "debt_settlement_flag",      
 "debt_settlement_flag_date", 
 "settlement_status",         
 "settlement_date")           

treatments <- vtreat::designTreatmentsC(Lcal,
                                c("id",               
"loan_amnt",                 
"funded_amnt",               
"funded_amnt_inv",           
"term",                  
"int_rate",                  
"installment",               
"grade",                     
"sub_grade",                
"emp_title",                 
"emp_length",                
"home_ownership",            
"annual_inc",                
"verification_status",       
"Issue_Month",               
"Issue_Year",                
"loan_status",               
"pymnt_plan",                
"url",                
"desc",                      
"purpose",                   
"title",                     
 "zip_code",                  
 "addr_state",                
 "dti",                       
 "delinq_2yrs",               
 "earliest_cr_line",          
 "fico_range_low",            
 "fico_range_high",           
 "inq_last_6mths",            
 "open_acc",                  
"pub_rec",                   
 "revol_bal",                 
 "revol_util",                
 "total_acc",                 
"initial_list_status",       
 "out_prncp",                 
 "out_prncp_inv",             
"total_pymnt",               
"total_pymnt_inv",           
"total_rec_prncp",           
"total_rec_int",            
"total_rec_late_fee",        
"recoveries",                
"collection_recovery_fee",   
"last_pymnt_d",              
"last_pymnt_amnt",           
"next_pymnt_d",              
"last_credit_pull_d",      
"last_fico_range_high",      
"last_fico_range_low",       
"collections_12_mths_ex_med",
 "policy_code",               
 "application_type",          
 "verification_status_joint", 
 "acc_now_delinq",            
 "tot_coll_amt",              
 "tot_cur_bal",               
 "total_rev_hi_lim",          
 "acc_open_past_24mths",      
 "avg_cur_bal",               
 "bc_open_to_buy",            
 "bc_util",                   
 "chargeoff_within_12_mths",  
 "delinq_amnt",               
"mo_sin_old_il_acct",        
 "mo_sin_old_rev_tl_op",      
 "mo_sin_rcnt_rev_tl_op",     
 "mo_sin_rcnt_tl",            
 "mort_acc",                  
 "mths_since_recent_bc",      
 "mths_since_recent_inq",     
 "num_accts_ever_120_pd",     
 "num_actv_bc_tl",            
 "num_actv_rev_tl",           
 "num_bc_sats",               
 "num_bc_tl",                 
 "num_il_tl",                 
 "num_op_rev_tl",             
 "num_rev_accts",             
 "num_rev_tl_bal_gt_0",       
 "num_sats",                  
 "num_tl_120dpd_2m",          
 "num_tl_30dpd",              
 "num_tl_90g_dpd_24m",        
 "num_tl_op_past_12m",        
 "pct_tl_nvr_dlq",            
 "percent_bc_gt_75",          
 "pub_rec_bankruptcies",      
 "tax_liens",                 
 "tot_hi_cred_lim",           
 "total_bal_ex_mort",         
 "total_bc_limit",            
 "total_il_high_credit_limit",
 "sec_app_earliest_cr_line",  
 "hardship_flag",             
 "hardship_type",             
 "hardship_reason",          
 "hardship_status",           
 "hardship_start_date",       
 "hardship_end_date",         
 "payment_plan_start_date",   
 "hardship_loan_status",      
 "disbursement_method",       
 "debt_settlement_flag",      
 "debt_settlement_flag_date", 
 "settlement_status",         
 "settlement_date",
'chance_default'
),
'chance_default',
outcometarget=TRUE,
verbose=FALSE)
```


### 3.c) apply the treatment plan to the treatment data set.

```{r}
TrainTreated <- vtreat::prepare(treatments,
                                 Ltrain,
                                 pruneSig=NULL)
```








```{r}
transform_spec <- vtreat::BinomialOutcomeTreatment(
    var_list = setdiff(colnames(d), c('y', 'yc')),  # columns to transform
    outcome_name = 'yc',                            # outcome variable
    outcome_target = TRUE                           # outcome of interest
)
```

### apply your fit Prepare to fit to the transform.

```{r}
unpack[
  treatment_plan = treatments,
  d_prepared = cross_frame
  ] <- fit_prepare(transform_spec, d)     

# list the derived variables
get_feature_names(treatment_plan)
```




I will also include examples of the past procedures for Vtreat using Mount and Zumel's other example (classfication example (https://github.com/WinVector/vtreat/blob/master/Examples/Classification/Classification.md).
